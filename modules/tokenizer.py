from nltk.tokenize import word_tokenize

class Tokenizer:
    def tokenize(self, text):
        return word_tokenize(text)
